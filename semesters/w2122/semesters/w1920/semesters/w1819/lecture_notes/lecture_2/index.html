<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.13.0 by Michael Rose
  Copyright 2013-2018 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE.txt
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Lecture 2: Sampling and Interpolation | CS236860: Digital Image Processing</title>
<meta name="description" content="Dirac’s delta, Sampling Theorem, Interpolation">


  <meta name="author" content="Prof. Alex Bronstein">


<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="CS236860: Digital Image Processing">
<meta property="og:title" content="Lecture 2: Sampling and Interpolation">
<meta property="og:url" content="https://vistalab-technion.github.io/cs236860/semesters/w1819/lecture_notes/lecture_2/">


  <meta property="og:description" content="Dirac’s delta, Sampling Theorem, Interpolation">











  

  


<link rel="canonical" href="https://vistalab-technion.github.io/cs236860/semesters/w1819/lecture_notes/lecture_2/">







  <script type="application/ld+json">
    {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "VISTA Lab",
      "url": "https://vistalab-technion.github.iocs236860/semesters/w1819",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/cs236860/semesters/w1819/feed.xml" type="application/atom+xml" rel="alternate" title="CS236860: Digital Image Processing Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/cs236860/semesters/w1819/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single text-justify wide">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="/cs236860/semesters/w1819/">CS236860: Digital Image Processing</a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/cs236860/semesters/w1819/info/" >Info</a>
            </li><li class="masthead__menu-item">
              <a href="/cs236860/semesters/w1819/lectures/" >Lectures</a>
            </li><li class="masthead__menu-item">
              <a href="/cs236860/semesters/w1819/tutorials/" >Tutorials</a>
            </li><li class="masthead__menu-item">
              <a href="/cs236860/semesters/w1819/hw/" >Assignments</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle Menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  

  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Lecture 2: Sampling and Interpolation">
    <meta itemprop="description" content="Dirac’s delta, Sampling Theorem, Interpolation">
    
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Lecture 2: Sampling and Interpolation
</h1>
          
            <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  53 minute read
</p>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right ">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> Contents</h4></header>
              <ul class="toc__menu">
  <li><a href="#notation">Notation</a></li>
  <li><a href="#diracs-delta">Dirac’s delta</a>
    <ul>
      <li><a href="#adjoint-operators">Adjoint operators</a></li>
      <li><a href="#distributions">Distributions</a></li>
      <li><a href="#delta-distribution">Delta distribution</a></li>
      <li><a href="#translation">Translation</a></li>
      <li><a href="#pointwise-product">Pointwise product</a></li>
      <li><a href="#convolution">Convolution</a></li>
      <li><a href="#fourier-transform">Fourier transform</a></li>
      <li><a href="#stretching">Stretching</a></li>
      <li><a href="#derivatives">Derivatives</a></li>
    </ul>
  </li>
  <li><a href="#diracs-bed">Dirac’s bed</a>
    <ul>
      <li><a href="#diracs-bed-1">Dirac’s bed</a></li>
      <li><a href="#pointwise-product-1">Pointwise product</a></li>
      <li><a href="#convolution-1">Convolution</a></li>
      <li><a href="#poisson-summation-identity">Poisson summation identity</a></li>
    </ul>
  </li>
  <li><a href="#sampling-theorem">Sampling theorem</a>
    <ul>
      <li><a href="#lattices">Lattices</a></li>
      <li><a href="#sampling-theorem-on-a-lattice">Sampling theorem on a lattice</a></li>
      <li><a href="#anti-aliasing">Anti-aliasing</a></li>
    </ul>
  </li>
  <li><a href="#interpolation">Interpolation</a>
    <ul>
      <li><a href="#interpolation-kernels">Interpolation kernels</a></li>
    </ul>
  </li>
</ul>
            </nav>
          </aside>
        
        <h2 id="notation">Notation</h2>

<p>In our course, we will deal almost exclusively with real functions. A
scalar function will be denoted as $f : \RR^d \rightarrow \RR$,
$f({\bm{\mathrm{x}}})$, or simply $f$, with $d$ denoting the domain
dimension. $d$-dimensional multi-indices will be denoted by
${\bm{\mathrm{n}}} = (n_1,\dots,n_d) \in {\bm{\mathrm{Z}}}^d$. An
operator acting on a function will be denoted by $\mathcal{H}(f)$ or
simply $\mathcal{H}f$.</p>

<h2 id="diracs-delta">Dirac’s delta</h2>

<p>In what follows, we define a little bit of a technical machinery that
will have crucial importance in the rigorous treatment of sampling.</p>

<h3 id="adjoint-operators">Adjoint operators</h3>

<p>We start with a little digression. Let $\mathbb{U}$ and $\mathbb{V}$ be
two spaces equipped with inner products, and let
$\mathcal{A} : \mathbb{U} \rightarrow \mathbb{V}$ and
$\mathcal{B} : \mathbb{V} \rightarrow \mathbb{U}$ be two operators. If
for every $u \in \mathbb{U}$ and $v \in \mathbb{V}$ it holds that
$\langle \mathcal{A}u, v \rangle_{\mathbb{V}} = \langle u, \mathcal{B} v \rangle_{\mathbb{U}}$,
we will say that the operator $\mathcal{B}$ is the <em>adjoint</em> of
$\mathcal{A}$ and denote it by $\mathcal{B} = \mathcal{A}^\ast$. Adjoint
is the generalization of the notion of transpose (Hermitian transpose in
the complex case) of a matrix. An operator satisftying
$\mathcal{A}^\ast  = \mathcal{A}$ is said to be <em>self-adjoint</em> (think of
a symmetric matrix). Warning: it is tempting to confuse adjoint with
inverse, as both are operators from $\mathbb{V}$ to $\mathbb{U}$. These
are very different notions, coinciding only in the case of unitary
operators.</p>

<p>For example, the adjoint of the translation operator
$\tau_{\bm{\mathrm{p}}}$ can be immediately derived from</p>

<script type="math/tex; mode=display">\begin{aligned}
\langle \tau_{\bm{\mathrm{p}}}f, g \rangle = \int_{\RR^d} f(\bm{\mathrm{x}} - \bm{\mathrm{p}}) g^\ast (\bm{\mathrm{x}}) d\bm{\mathrm{x}} = \int_{\RR^d} f(\bm{\mathrm{y}}) g^\ast (\bm{\mathrm{y}}-(-\bm{\mathrm{p}}) ) d\bm{\mathrm{y}}  = \langle f, \tau_{-\bm{\mathrm{p}}}g \rangle,
\end{aligned}</script>

<p>from where $\tau_{\bm{\mathrm{p}}}^\ast = \tau_{-\bm{\mathrm{p}}}$
(verify this by thinking of $\tau_{\bm{\mathrm{p}}}$ as of a Toeplitz
matrix and taking its transpose). As a more general example, consider
operator convolving the input function with a given real-valued function
$h$. Then,</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
\langle h \ast f, g \rangle &= \int_{\RR^d} \left(  \int_{\RR^d} h(\bm{\mathrm{x}}-\bm{\mathrm{x}}') f(\bm{\mathrm{x}}') d\bm{\mathrm{x}}' \right) g^\ast (\bm{\mathrm{x}}) d\bm{\mathrm{x}}  \\
&= \int_{\RR^d}f(\bm{\mathrm{x}}') \left(  \int_{\RR^d} h(\bm{\mathrm{x}}- \bm{\mathrm{x}}') g(\bm{\mathrm{x}}) d\bm{\mathrm{x}} \right)^\ast d\bm{\mathrm{x}}' \\
&= \int_{\RR^d}f(\bm{\mathrm{x}}') \left(  \int_{\RR^d} \bar{h}(\bm{\mathrm{x}}'-\bm{\mathrm{x}}) g(\bm{\mathrm{x}}) d\bm{\mathrm{x}} \right)^\ast d\bm{\mathrm{x}}' = \langle f, \bar{h} \ast g \rangle,
\end{aligned} %]]></script>

<p>from where the adjoint of $h \ast f$ is $\bar{h} \ast f$, with
$\bar{h}({\bm{\mathrm{x}}}) = h(-{\bm{\mathrm{x}}})$.</p>

<p>Yet another example: it is straightforward to see that the point-wise
product with a given real-valued function $h$ is self-adjoint, since</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
\langle h \cdot f, g \rangle &= \int_{\RR^d} h({\bm{\mathrm{x}}}) f({\bm{\mathrm{x}}}) g^\ast ({\bm{\mathrm{x}}}) d{\bm{\mathrm{x}}}\\
 &= \int_{\RR^d}  f({\bm{\mathrm{x}}}) h^\ast ({\bm{\mathrm{x}}}) g^\ast ({\bm{\mathrm{x}}}) d{\bm{\mathrm{x}}}\\
 &= \langle f, h \cdot g \rangle.
\end{aligned} %]]></script>

<p>Finally, let us derive the adjoint of the Fourier transform:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
\langle \mathcal{F} f, G \rangle &= \int_{\RR^d}  \left(  \int_{\RR^d} f({\bm{\mathrm{x}}}) e^{-2\pi \ii \, {\bm{\mathrm{\xi}}}^\Tr {\bm{\mathrm{x}}}}  d{\bm{\mathrm{x}}} \right) G^\ast ({\bm{\mathrm{\xi}}}) d{\bm{\mathrm{\xi}}}\\ 
&= \int_{\RR^d}  f({\bm{\mathrm{x}}}) \left(  \int_{\RR^d} G ({\bm{\mathrm{\xi}}})  e^{2\pi \ii \, {\bm{\mathrm{\xi}}}^\Tr {\bm{\mathrm{x}}}}  d{\bm{\mathrm{\xi}}}  \right)^\ast d{\bm{\mathrm{x}}} \\
&= \langle  f, \mathcal{F}^{-1} G \rangle.
\end{aligned} %]]></script>

<p>We observe that $\mathcal{F}^\ast = \mathcal{F}^{-1}$, implying that $\mathcal{F}$
is a unitary transformation (an isometry). From this geometric
properties, <em>Plancherel’s identity</em> follows:</p>

<script type="math/tex; mode=display">\langle f, g \rangle = \langle F, G \rangle,</script>

<p>with
$F = \mathcal{F} f$ and $G = \mathcal{F} g$. In the particular case of
$g=f$, we obtain the celebrate <em>Parseval’s identity</em>,</p>

<script type="math/tex; mode=display">\|f\|^2 = \langle f, f \rangle = \langle F, F \rangle = \| F \|^2,</script>

<p>which is precisely what <em>isometry</em> means.</p>

<p>We will see more adjoint operators in the sequel.</p>

<h3 id="distributions">Distributions</h3>

<p>Let $f : \RR^d \rightarrow \RR$ be given function. A funny way to
represent it is to consider the action of the inner product with $f$ on
a real-valued test function<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup> $\psi$:</p>

<script type="math/tex; mode=display">F(\psi) = \langle f, \psi \rangle = \int_{\RR^d} f({\bm{\mathrm{x}}}) \psi({\bm{\mathrm{x}}}) d{\bm{\mathrm{x}}}.</script>

<p>Essentially, we defined a linear functional assigning each test function
a real scalar. Let us now think of a probability measure $\mu$ on
$\RR^d$. A way to represent the measure is to consider its moments of
the form <script type="math/tex">M(\psi) = \mathbb{E}_\mu \psi = \int \psi d\mu</script> (we can
think of the previous example as a realization of the latter one if we
think of $f$ as the probability density function embodying $\mu$).
Again, a linear functional is used to represent a probability measure.</p>

<p>A general linear functional assigning real scalars to tests functions is
called a <em>distribution</em>. Because of our first example, we will denote
the action of such a functional on a test function using the inner
product notation, <script type="math/tex">L(\psi) = \langle L, \psi \rangle.</script> Beware: this is
just a convenient notation. Of course, $L$ is not a function and the
above inner product makes no sense. We simply <em>define</em> it to assume the
value of $L(\psi)$. The notation is convenient because it allows to
define in a consistent way what it means to apply an operator to a
distribution.</p>

<p>Let us return to our first example of the distribution
$F(\psi) = \langle f, \psi \rangle$ representing a function $f$, and let
us now be given an operator $\mathcal{A}$. What is the meaning of
“$\mathcal{A}F$”? Rigorously, $F$ is not a function and the latter
expression makes no sense; yet, can we <em>attribute</em> it a meaning? In our
particular case, we can interpret $\mathcal{A}F$ as a new distribution</p>

<script type="math/tex; mode=display">\mathcal{A}F)(\psi) = \langle \mathcal{A} f, \psi \rangle = \langle  f, \mathcal{A}^\ast \psi \rangle.</script>

<p>We will now carry this trick with the adjoint to the general case: given
a distribution $L$, we <em>define</em></p>

<script type="math/tex; mode=display">(\mathcal{A} L)(\psi) = \langle \mathcal{A} L, \psi \rangle = \langle  L, \mathcal{A}^\ast \psi \rangle = L(\mathcal{A}^\ast \psi).</script>

<p>Note that the left hand side is just convenient notation that rigorously
speaking has no mathematical sense. The right hand side, on the contrary
is well-defined: no operator is acting on $L$; instead, the adjoint
operator acts on the test function. This essentially gives rigorous
sense and meaning to “$\mathcal{A} L$”. With these understandings in
mind, let us now introduce a very important distribution and study its
properties.</p>

<h3 id="delta-distribution">Delta distribution</h3>

<p>The distribution $\delta(\psi) = \psi(0)$ is called the <em>Dirac delta</em>.
Using the inner product notation, we can write</p>

<script type="math/tex; mode=display">\delta(\psi) = \langle \delta, \psi \rangle = \int_{\RR^d} \delta({\bm{\mathrm{x}}}) \psi(x) d{\bm{\mathrm{x}}}.</script>

<p>While the second expression is just a syntactic sugar to $\delta(\psi)$,
the third one is simply nonsensensical: $\delta$ is not a function and
cannot be integrated; furthermore, there exists no such a function the
integration with which would yield the value of $\psi$ at
${\bm{\mathrm{x}}} = 0$.<sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup> ! Yet, engineering books are full with such
a notation, referring to $\delta$ as to a “generalized function”.</p>

<p>Using our definition of
$(\mathcal{A} \delta)(\psi) = \delta(\mathcal{A}^\ast \psi)$, we can
readily list a few important properties of the delta (it only takes to
derive the adjoint operator).</p>

<h3 id="translation">Translation</h3>

<script type="math/tex; mode=display">(\tau_{\bm{\mathrm{p}}} \delta)(\psi) = \delta( \tau_{\bm{\mathrm{p}}}^\ast \psi) = \delta( \tau_{-\bm{\mathrm{p}}} \psi) = \left. \psi(\bm{\mathrm{x}} + \bm{\mathrm{p}}) \right| _{\bm{\mathrm{x}}=0} = \psi(\bm{\mathrm{p}}).</script>

<h3 id="pointwise-product">Pointwise product</h3>

<p>Given a function $h : \RR^d \rightarrow \RR$ and using the fact that
pointwise product with a real-valued function is self-adjoint, we obtain</p>

<script type="math/tex; mode=display">(h \cdot \delta)(\psi) = \delta( h \cdot \psi) = f(0) \psi(0) = h(0)\, \delta(\psi).</script>

<h3 id="convolution">Convolution</h3>

<p>Given a function $h : \RR^d \rightarrow \RR$ and using the fact that the
adjoint of convolution with $h$ is the convolution with
$\bar{h}({\bm{\mathrm{x}}}) = h(-{\bm{\mathrm{x}}})$ yields</p>

<script type="math/tex; mode=display">(h \ast \delta)(\psi) = \delta( \bar{h} \ast \psi) =   (\bar{h} \ast \psi)(0) = \int_{\RR^d} h(\bm{\mathrm{x}}-0) \psi (\bm{\mathrm{x}}) d\bm{\mathrm{x}} = \langle h, \psi \rangle.</script>

<p>Note that the right hand side is a distribution representing the
function $h$. With some abuse of notation, we can say that the
convolution of $\delta$ with a function $h$ ceases to be distribution
and becomes the function $h$ itself. Delta is actually the only
distribution acting as an identity element, a fact allowing to define a
group of functions with convolution serving as the group operation.</p>

<h3 id="fourier-transform">Fourier transform</h3>

<p>Using the unitarity of the Fourier transform,</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
(\mathcal{F} \delta)(\Psi) &=& ( \delta)(\mathcal{F}^\ast \Psi) = (\mathcal{F}^{-1} \Psi)(0) = \int_{\RR^d} \Psi({\bm{\mathrm{\xi}}}) e^{ 2\pi \ii \, {\bm{\mathrm{\xi}}}^\Tr {\bm{\mathrm{0}}} } d{\bm{\mathrm{\xi}}}
=  \int_{\RR^d} \Psi({\bm{\mathrm{\xi}}}) \mathbbl{1}({\bm{\mathrm{\xi}}}) d{\bm{\mathrm{\xi}}} = \langle \Psi, \mathbbl{1} \rangle,
\end{aligned} %]]></script>

<p>where $\mathbbl{1}({\bm{\mathrm{\xi}}}) = 1$ is a constant function.
Again, the last expression is a distribution representing the constant
function $\mathbbl{1}$, so we can write (with some abuse of notation):
$ \delta  \fff \mathbbl{1}$. Combining this result with the
translation/modulation property leads to</p>

<script type="math/tex; mode=display">\begin{aligned}
{\tau_{\bm{\mathrm{p}}} \delta \fff \phi_{\bm{\mathrm{p}}} }
\end{aligned}</script>

<h3 id="stretching">Stretching</h3>

<p>In order to see the action of the stretrching operator
$\mathcal{S}_{\bm{\mathrm{A}}} : f(\bm{\mathrm{x}}) \mapsto f(\bm{\mathrm{A}}\bm{\mathrm{x}})$ on the delta, let us first derive its adjoint:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
\langle \mathcal{S}_{\bm{\mathrm{A}}} f, g \rangle &= \int_{\RR^d} f(\bm{\mathrm{A}} \bm{\mathrm{x}}) g(\bm{\mathrm{x}}) d\bm{\mathrm{x}}\\
 &= \int_{\RR^d} f(\bm{\mathrm{y}}) g(\bm{\mathrm{A}}^{-1} \bm{\mathrm{y}}) \frac{d\bm{\mathrm{y}}}{| \det \bm{\mathrm{A}} |} \\
 &= \langle f , \frac{ \mathcal{S}_{\bm{\mathrm{A}}}^{-1} }{ | \det {\bm{\mathrm{A}}} | } g \rangle,
\end{aligned} %]]></script>

<p>from where
$ {\mathcal{S} _\bm{\mathrm{A}}}^\ast = \frac{ \mathcal{S} _{\bm{\mathrm{A}}}^{-1} }{ | \det {\bm{\mathrm{A}}} | } $.</p>

<p>Invoking the definion of an operator acting on a distribution,</p>

<script type="math/tex; mode=display">( \mathcal{S}_{\bm{\mathrm{A}}} \delta)(\psi) = \delta( \mathcal{S}_{\bm{\mathrm{A}}}^\ast \psi) = \left. \frac{\psi(\bm{\mathrm{A}}^{-1} \bm{\mathrm{x}})}{| \det \bm{\mathrm{A}} |} \right|_{\bm{\mathrm{x}} =0} =  \frac{\psi(0)}{| \det \bm{\mathrm{A}} |}   =  \frac{ \delta(\psi) }{| \det \bm{\mathrm{A}} |}.</script>

<p>Informally, thinking of $\delta$ as of a “function”, we can write
$\delta({\bm{\mathrm{A}}}{\bm{\mathrm{x}}})  = \frac{ \delta({\bm{\mathrm{x}}}) }{| \det {\bm{\mathrm{A}}} |}$.
A straightforward corollary is that $\delta$ is invariant to rotation.</p>

<h3 id="derivatives">Derivatives</h3>

<p>In order to define delta’s derivatives, let us first examine the adjoint
of the derivative operator. For the sake of clairity, let us first
consider the partial derivative with respect to the first coordinate,
$\partial_1 f = \frac{\partial}{\partial x_1} f$. Using integration by
parts yields</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
\langle \partial_1 f, g \rangle &= \int_{\RR^d} \partial_1 f({\bm{\mathrm{x}}}) g({\bm{\mathrm{x}}}) d{\bm{\mathrm{x}}} \\
&= \left. \int_{\RR^{d-1}}  f({\bm{\mathrm{x}}}) g({\bm{\mathrm{x}}}) dx_2 \cdots dx_d \right|_{x_1= -\infty}^{x_1 = \infty} -   \int_{\RR^d}  f({\bm{\mathrm{x}}})\partial_1 g({\bm{\mathrm{x}}}) d{\bm{\mathrm{x}}}.
\end{aligned} %]]></script>

<p>By asserting that the functions $f$ and $g$ vanish at infinity, we
obtain</p>

<script type="math/tex; mode=display">\begin{aligned}
\langle \partial_1 f, g \rangle = \langle  f, - \partial_1 g \rangle.
\end{aligned}</script>

<p>In the same manner, for any partial derivative operator of order $n$,</p>

<script type="math/tex; mode=display">\partial_{\bm{\mathrm{n}}} f = \frac{\partial^{n_1}}{\partial x_1^{n_1}} \cdots \frac{\partial^{n_d}}{\partial x_d^{n_d}} f,</script>

<p>parametrized by the multi-index ${\bm{\mathrm{n}}}$, it is
straightforward to show that
$\partial_{\bm{\mathrm{n}}}^\ast = (-1)^{|\bm{\mathrm{n}}|} \partial_{\bm{\mathrm{n}}}$,
where $|\bm{\mathrm{n}}| = n_1 + \cdots + n_d$. With this result, we
can now write</p>

<script type="math/tex; mode=display">( \partial_{\bm{\mathrm{n}}}  \delta)(\psi) = \delta( \partial_{\bm{\mathrm{n}}}^\ast \psi) = (-1)^{|\bm{\mathrm{n}}|} (\partial_{\bm{\mathrm{n}}} \psi )(0).</script>

<h2 id="diracs-bed">Dirac’s bed</h2>

<h3 id="diracs-bed-1">Dirac’s bed</h3>

<p>Equipped with the delta and its basic properties, we are ready to define
a new distribution that we will call a <em>Dirac’s bed</em> or a <em>bed of
impulses</em> (on the integer lattice; we will generalize this definition in
the sequel):</p>

<script type="math/tex; mode=display">\bed = \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d} \tau_{\bm{\mathrm{p}}} \delta.</script>

<p>The importance of this distribution comes from the following two
properties:</p>

<h3 id="pointwise-product-1">Pointwise product</h3>

<p>Given a real-valued function $f$,</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
(f \cdot \bed)(\psi) &=  \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d} \tau_{\bm{\mathrm{p}}} (f \cdot \delta)(\psi)
= \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d}  (\tau_{\bm{\mathrm{p}}} \delta)(f \cdots \psi) = 
\sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d}   \delta(\tau_{-\bm{\mathrm{p}}} (f \cdot \psi)) = \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d}   f({\bm{\mathrm{p}}}) \psi(\bm{\mathrm{p}}) \nonumber\\
&=  \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d}   f(p) (\tau_{\bm{\mathrm{p}}} \delta)(\psi).
\end{aligned} %]]></script>

<p>Therefore, we can write</p>

<script type="math/tex; mode=display">\begin{aligned}
 f \cdot \bed = \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d}   f(p) \, \tau_{\bm{\mathrm{p}}} \delta  
\end{aligned}</script>

<p>Note that the resulting distribution is still a bed of impulses, but now
each impulse placed at point ${\bm{\mathrm{p}}}$ of the integer lattice
is scaled by the value of the function $f$ at that point. This is a
convenient way to represent the action of <em>sampling</em>.</p>

<h3 id="convolution-1">Convolution</h3>

<p>As in the previous case,</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
(f \ast \bed)(\psi) &=  \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d} \tau_{\bm{\mathrm{p}}} (f \ast \delta)(\psi)
= \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d}  (\tau_{\bm{\mathrm{p}}} \delta)(\bar{f} \ast \psi) = 
\sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d}   (\bar{f} \ast \psi)(\bm{\mathrm{p}}) \\
&= \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d} \int_{\RR^d} f(\bm{\mathrm{x}}-\bm{\mathrm{p}}) g(\bm{\mathrm{x}}) d\bm{\mathrm{x}}\\
&= \int_{\RR^d} \left( \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d}  f(\bm{\mathrm{x}}-\bm{\mathrm{p}}) \right) g(\bm{\mathrm{x}}) d\bm{\mathrm{x}} \\
&= \langle \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d}  f(\bm{\mathrm{x}}-\bm{\mathrm{p}}), g \rangle.
\end{aligned} %]]></script>

<p>Note that the resulting distribution is no more a bed of impulses but
rather the periodic function</p>

<script type="math/tex; mode=display">\begin{aligned}
f \ast \bed =\sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d}  f(\bm{\mathrm{x}}-\bm{\mathrm{p}}) 
\end{aligned}</script>

<p>In other words, convolution with a bed of impulses is akin to
<em>periodization</em> of the function.</p>

<h3 id="poisson-summation-identity">Poisson summation identity</h3>

<p>Let $\psi$ be a test function and let us define it periodized version</p>

<script type="math/tex; mode=display">\tilde{\psi}(\bm{\mathrm{x}}) = (\bed \ast \psi)(\bm{\mathrm{x}}) = \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d}  \psi(\bm{\mathrm{x}}-\bm{\mathrm{p}}).</script>

<p>As a periodic function, it can be represented as a ($d$-dimensional)
Fourier series</p>

<script type="math/tex; mode=display">\tilde{\psi}(\bm{\mathrm{x}}) = \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d} c_{\bm{\mathrm{p}}}  e^{2\pi \ii \, \bm{\mathrm{p}}^\Tr \bm{\mathrm{x}}}</script>

<p>with</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
c_{\bm{\mathrm{p}}} &= \int_{[0,1]^d}  \tilde{\psi}(\bm{\mathrm{x}})  e^{-2\pi \ii \, \bm{\mathrm{p}}^\Tr \bm{\mathrm{x}}} d\bm{\mathrm{x}} =   \int_{[0,1]^d} \sum_{\bm{\mathrm{q}} \in \mathbb{Z}^d}  \psi(\bm{\mathrm{x}}-\bm{\mathrm{q}})  e^{-2\pi \ii \, \bm{\mathrm{p}}^\Tr \bm{\mathrm{x}}} d\bm{\mathrm{x}} \\
&= \sum_{\bm{\mathrm{q}} \in \mathbb{Z}^d}   \int_{[0,1]^d} \psi(\bm{\mathrm{y}}) e^{-2\pi \ii \, \bm{\mathrm{p}}^\Tr (\bm{\mathrm{y}} + \bm{\mathrm{q}})} d\bm{\mathrm{y}}  \\
&= \sum_{\bm{\mathrm{q}} \in \mathbb{Z}^d}   \int_{[0,1]^d} \psi(\bm{\mathrm{y}}) e^{-2\pi \ii \, \bm{\mathrm{p}}^\Tr \bm{\mathrm{y}} } d \bm{\mathrm{y}}   \, e^{2\pi \ii \, \bm{\mathrm{p}}^\Tr \bm{\mathrm{q}}} \\
&= \int_{\RR^d} \psi(\bm{\mathrm{y}}) e^{-2\pi \ii \, \bm{\mathrm{p}}^\Tr \bm{\mathrm{y}} } d\bm{\mathrm{y}} = (\mathcal{F}\psi)(\bm{\mathrm{p}}).
\end{aligned} %]]></script>

<p>Therefore,</p>

<script type="math/tex; mode=display">\tilde{\psi}(\bm{\mathrm{x}}) = \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d}  (\mathcal{F}\psi)(\bm{\mathrm{p}})  e^{2\pi \ii \, \bm{\mathrm{p}}^\Tr \bm{\mathrm{x}}}.</script>

<p>Substituting $\bm{\mathrm{x}} = \bm{\mathrm{0}}$, we obtain</p>

<script type="math/tex; mode=display">\tilde{\psi}(\bm{\mathrm{0}}) =  \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d}  \psi(-\bm{\mathrm{p}}) = \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d}  \psi(\bm{\mathrm{p}})</script>

<p>as well as</p>

<script type="math/tex; mode=display">\tilde{\psi}(\bm{\mathrm{0}}) =  \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d}  (\mathcal{F}\psi)(\bm{\mathrm{p}})  e^{2\pi \ii \, \bm{\mathrm{p}}^\Tr \bm{\mathrm{0}}} = \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d}  (\mathcal{F}\psi)(\bm{\mathrm{p}}).</script>

<p>This leads to the following amazing result known as the <em>Poisson
summation formula</em>:</p>

<script type="math/tex; mode=display">\sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d}  (\mathcal{F}\psi)(\bm{\mathrm{p}}) = \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d}  \psi(\bm{\mathrm{p}}).</script>

<p>The following corollary follows directly:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
\langle \mathcal{F} \bed, \Psi \rangle &= \langle  \bed,  \mathcal{F}^{-1} \Psi \rangle = \langle  \bed,  \psi \rangle  
= \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d}  \psi(\bm{\mathrm{p}}) = \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d}  \Psi({\bm{\mathrm{p}}}) = \langle \bed, \Psi \rangle
\end{aligned} %]]></script>

<p>where we denote as usual $\Psi = \mathcal{F} \psi$. In other words,</p>

<script type="math/tex; mode=display">\begin{aligned}
  \mathcal{F} \bed = \bed 
\end{aligned}</script>

<p>Combining this result with the convolution/product duality, we obtain
the following duality between sampling and periodization:</p>

<script type="math/tex; mode=display">\begin{aligned}
{ \bed \ast f \fff \bed \cdot F }
\end{aligned}</script>

<p>In other words, sampling the signal in the space domain result in the
periodization of the Fourier transform, and vice versa, periodization of
the signal in the space domain results in a sampled Fourier transform.
The latter is a mere justification of the fact that periodic functions
can be represented as Fourier series that have a discrete set of spatial
frequencies. The former leads to the famous sampling theorem.</p>

<h2 id="sampling-theorem">Sampling theorem</h2>

<p>Sampling a function on the integer lattice is descrbied by the following
distribution</p>

<script type="math/tex; mode=display">\bed \cdot f = \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d} f(\bm{\mathrm{p}}) \tau_{\bm{\mathrm{p}}} \delta.</script>

<p>Our previous result tells us that the Fourier transform of this
distribution is the periodization of the Fourier transform
$F({\bm{\mathrm{\xi}}}) = (\mathcal{F}f)({\bm{\mathrm{\xi}}})$,</p>

<script type="math/tex; mode=display">\tilde{F}(\bm{\mathrm{\xi}}) =(\bed \ast F)(\bm{\mathrm{\xi}}) = \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d}  F(\bm{\mathrm{\xi}} - \bm{\mathrm{p}}).</script>

<p>It it happens that
$\mathrm{supp}(F) = {  {\bm{\mathrm{\xi}}} : F({\bm{\mathrm{\xi}}}) \ne 0 } \not\subset \left[-\frac{1}{2},\frac{1}{2}\right]^d$,
in the above summation, the shifted replicas of the Fourier transforms
of $f$ will overlap forever losing the information contained in them and
producing originally inexistent content at lower frequencies. This
phenomenon is called <em>aliasing</em>.</p>

<p>On the other hand, if $\mathrm{supp}(F) \subset \left[-\frac{1}{2},\frac{1}{2}\right]^d$, the
shifted replicas will not overlap and no information loss will occur.</p>

<p>The original Fourier transform of $f$ can be recovered from $\tilde{F}$
by multiplying the latter with the box function taking the value of $1$
on $\left[-\frac{1}{2},\frac{1}{2}\right]^d$ and $0$ elsewhere:</p>

<p><script type="math/tex">F = \tilde{F} \cdot \mathrm{box}</script>.</p>

<p>We have seen already the following duality <script type="math/tex">\mathrm{box} \fff \mathrm{sinc},</script> from which we obtain</p>

<script type="math/tex; mode=display">f(\bm{\mathrm{x}}) = (\bed \cdot f) \ast \mathrm{sinc} (\bm{\mathrm{x}}) =  \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d} f(\bm{\mathrm{p}}) \tau_{\bm{\mathrm{p}}} \delta \ast \mathrm{sinc}(\bm{\mathrm{x}}) = \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d} f(\bm{\mathrm{p}}) \, \mathrm{sinc}(\bm{\mathrm{x}} - \bm{\mathrm{p}}).</script>

<p>This result tells us that if the function $f$ has
$\mathrm{supp}(F) \subset \left[-\frac{1}{2},\frac{1}{2}\right]^d$ (such
functions are called <em>band limited</em>), we can perfectly reconstruct it
from its sampled version by means of the above series (which is
sometimes called the <em>cardinal series</em>), and is known as the
(Kotelnikov-Whittaker-Nyquist-Hartley-Shannon) <em>sampling theorem</em>.</p>

<p>In what follows, we extend this result to sampling on a general lattice.</p>

<h3 id="lattices">Lattices</h3>

<p>The sampling and periodization we dealt with so far was defined on the
so-called <em>integer lattice</em>, $\mathbb{Z}^d$. A more general lattice is
defined by means of a regular (=non-singular) linear transformation of
$\mathbb{Z}^d$:</p>

<script type="math/tex; mode=display">\mathcal{L} = {\bm{\mathrm{A}}}\mathbb{Z}^d = \{  z_1 {\bm{\mathrm{a}}}_1 + \cdots + z_d {\bm{\mathrm{a}}}_d : {\bm{\mathrm{z}}} \in \mathbb{Z}^d \}.</script>

<p>To perform sampling on $\mathcal{L} = {\bm{\mathrm{A}}}\mathbb{Z}^d$, we
define</p>

<script type="math/tex; mode=display">\bed_{\mathcal{L}} = \sum_{\bm{\mathrm{p}} \in \mathcal{L}} \tau_{\bm{\mathrm{p}}} \delta = \sum_{\bm{\mathrm{q}} \in \mathbb{Z}^d}  \tau_{\bm{\mathrm{A}}\bm{\mathrm{q}}} \delta.</script>

<p>Since</p>

<p><script type="math/tex">(\tau_{\bm{\mathrm{A}}\bm{\mathrm{q}}} f)(\bm{\mathrm{x}}) = f(\bm{\mathrm{x}}-\bm{\mathrm{A}}\bm{\mathrm{q}}) = f(\bm{\mathrm{A}}(\bm{\mathrm{A}}^{-1}(\bm{\mathrm{x}}-\bm{\mathrm{A}}\bm{\mathrm{q}}))) = ((\mathcal{S}_{\bm{\mathrm{A}}^{-1}} \tau_{\bm{\mathrm{q}}}  \mathcal{S}_{\bm{\mathrm{A}}}) f)(\bm{\mathrm{x}})</script>,</p>

<p>we have</p>

<script type="math/tex; mode=display">\bed_{\mathcal{L}} = \sum_{\bm{\mathrm{q}} \in \mathbb{Z}^d}  \mathcal{S}_{\bm{\mathrm{A}}^{-1}} \tau_{\bm{\mathrm{q}}} \mathcal{S}_{\bm{\mathrm{A}}}  \delta 
= \frac{\mathcal{S}_{\bm{\mathrm{A}}^{-1}}}{ |\det \bm{\mathrm{A}} |}  \sum_{\bm{\mathrm{q}} \in \mathbb{Z}^d}   \tau_{\bm{\mathrm{q}}} \delta =  \frac{\mathcal{S}_{\bm{\mathrm{A}}^{-1}}}{ \mathrm{vol}\, \mathcal{L} } \bed,</script>

<p>where by $\mathrm{vol}\, \mathcal{L}$ we denote the volume of the
structural element of the lattice.</p>

<p>Using the stretching property of the Fourier transform,</p>

<script type="math/tex; mode=display">\mathcal{S}_{\bm{\mathrm{A}}} \fff \frac{\mathcal{S}_{\bm{\mathrm{A}}^{-\Tr}}}{ | \det \bm{\mathrm{A}} | },</script>

<p>we have</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
\mathcal{F} \bed_{\mathcal{L}} &= \frac{1}{ | \det \bm{\mathrm{A}} | } \mathcal{F} \mathcal{S}_{\bm{\mathrm{A}}^{-1}}\bed\\
&=
  \frac{1}{ | \det \bm{\mathrm{A}} | } \frac{1}{|  \det \bm{\mathrm{A}}^{-1} | } \mathcal{S}_{\bm{\mathrm{A}}^\Tr}  \mathcal{F} \bed \\
&= | \det \bm{\mathrm{A}}^{-1} | \frac{\mathcal{S}_{\bm{\mathrm{A}}^\Tr}}{ | \det \bm{\mathrm{A}}^{-1} |}   \bed \\
&=
  | \det \bm{\mathrm{A}}^{-1} | \, \bed_{\bm{\mathrm{A}}^{-\Tr} \mathbb{Z}^d}
\end{aligned} %]]></script>

<p>Note that the Fourier transform of a bed of impulses on the lattice
$\bm{\mathrm{A}}\mathbb{Z}^d$ is proportional to a bed of impulses on
the lattice $\bm{\mathrm{A}}^{-\Tr}\mathbb{Z}^d$. Note that since
$(\bm{\mathrm{A}}^{-\Tr})^\Tr \bm{\mathrm{A}} = \bm{\mathrm{A}}^{-1} \bm{\mathrm{A}} = \bm{\mathrm{I}}$,
the columns of ${\bm{\mathrm{A}}}$ and ${\bm{\mathrm{A}}}^{-\Tr}$ are
orthonormal. It is convenient to define this particular lattice as the
<em>dual</em> or <em>reciprocal</em> of $\mathcal{L}$,</p>

<script type="math/tex; mode=display">\mathcal{L}^\ast = \bm{\mathrm{A}}^{-\Tr} \mathbb{Z}^d.</script>

<p>Note that</p>

<script type="math/tex; mode=display">\mathrm{vol}\, \mathcal{L}^\ast = |\det {\bm{\mathrm{A}}}^{-1} | = \frac{1}{\mathrm{vol}\, \mathcal{L}}.</script>

<p>In this notation, we can write 
<script type="math/tex">\begin{aligned}
 \bed_{\mathcal{L}}  \fff  \mathrm{vol}\, \mathcal{L}^\ast \,  \bed_{\mathcal{L}^\ast}  
\end{aligned}</script></p>

<h3 id="sampling-theorem-on-a-lattice">Sampling theorem on a lattice</h3>

<p>Let ${\bm{\mathrm{A}}}$ be a regular matrix defining the lattice
$\mathcal{L} = \bm{\mathrm{A}} \mathbb{Z}^d$. We will denote by
$\mathcal{L}_0 = \bm{\mathrm{A}}\left[-\frac{1}{2},\frac{1}{2}\right]^d$
the <em>structural element</em> of the lattice, i.e., the smallest set such
that</p>

<script type="math/tex; mode=display">\bigcup_{\bm{\mathrm{p}} \in \mathcal{L} } (\bm{\mathrm{p}} + \mathcal{L}_0)  = \mathbb{R}^d.</script>

<p>We will say that a function $f$ is <em>$\mathcal{L}_0$-band limited</em> if
$ \mathrm{supp}(F) \subset\mathcal{L}_0$.</p>

<p>Let us denote
${\bm{\mathrm{B}}} = {\bm{\mathrm{A}}}^{-\Tr}$ and define
$g(\bm{\mathrm{x}}) = f(\bm{\mathrm{B}} \bm{\mathrm{x}}) = (\mathcal{S}_{\bm{\mathrm{B}}} f)(\bm{\mathrm{x}})$.</p>

<p>According to the stretching property of the Fourier transform,</p>

<script type="math/tex; mode=display">G(\bm{\mathrm{\xi}}) = \frac{1}{|\det \bm{\mathrm{B}}| } F(\bm{\mathrm{B}}^{-\Tr} \bm{\mathrm{\xi}})  = | \det \bm{\mathrm{A}} | \, F(\bm{\mathrm{A}}\bm{\mathrm{\xi}}).</script>

<p>Hence,</p>

<script type="math/tex; mode=display">\mathrm{supp}(G) = \{ {\bm{\mathrm{\xi}}} : F({\bm{\mathrm{A}}}{\bm{\mathrm{\xi}}}) \ne 0  \} = {\bm{\mathrm{A}}}^{-1}  \{ {\bm{\mathrm{\xi}}} : F({\bm{\mathrm{\xi}}}) \ne 0  \} = {\bm{\mathrm{A}}}^{-1} \mathrm{supp}(F) \subset \left[-\frac{1}{2},\frac{1}{2}\right]^d.</script>

<p>Hence, $g$ is band-limited on $\left[-\frac{1}{2},\frac{1}{2}\right]^d$
and we can write with
${\bm{\mathrm{y}}} = {\bm{\mathrm{B}}}{\bm{\mathrm{x}}}$</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
f(\bm{\mathrm{y}}) &= f(\bm{\mathrm{B}}\bm{\mathrm{x}}) = g(\bm{\mathrm{x}}) = \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d} g(\bm{\mathrm{p}}) \, \mathrm{sinc}(\bm{\mathrm{x}} - \bm{\mathrm{p}}) \\
&= \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d} g(\bm{\mathrm{p}}) \, \mathrm{sinc}(\bm{\mathrm{B}}^{-1} \bm{\mathrm{y}} - \bm{\mathrm{p}}) 
= \sum_{\bm{\mathrm{p}} \in \mathbb{Z}^d} g(\bm{\mathrm{p}}) \, \mathrm{sinc}(\bm{\mathrm{B}}^{-1} ( \bm{\mathrm{y}} - \bm{\mathrm{B}}\bm{\mathrm{p}})) \\
&= \sum_{\bm{\mathrm{q}} \in \bm{\mathrm{B}} \mathbb{Z}^d} g(\bm{\mathrm{B}}^{-1}\bm{\mathrm{q}}) \, \mathrm{sinc}(\bm{\mathrm{B}}^{-1} ( \bm{\mathrm{y}} - \bm{\mathrm{q}})) \\
&= \sum_{\bm{\mathrm{q}} \in \mathcal{L}^\ast } f(\bm{\mathrm{q}}) \, \mathrm{sinc}(\bm{\mathrm{A}}^{\Tr} ( \bm{\mathrm{y}} - \bm{\mathrm{q}}))
\end{aligned} %]]></script>

<p>In other words, a $\mathcal{L}_0$-band limited $f$ can be perfectly
reconstructed from its samples on $\mathcal{L}^\ast$.</p>

<h3 id="anti-aliasing">Anti-aliasing</h3>

<p>Many real-world signals such as images are not truly band-limited
(though do exhibit decaying spectrum). In order to avoid aliasing at
sampling, the signal has to be made band-limited. If sampling occurs on
lattice $\mathcal{L}^\ast$, the signal has to be $\mathcal{L}$
band-limited in order to allow perfect reconstruction. A real signal is
made band-limited by applying a low pass <em>anti-aliasing filter</em>
immediately prior to sampling. The filter has to be applied in the
analog domain – in electronics when sampling a one-dimensional time
signal, or in optics when sampling an image. A lens has a natural high
frequency cut-off due to diffraction limit, which acts as an
anti-aliasing filter.</p>

<p>The ideal anti-aliasing filter should have the frequency response
$H_{\mathcal{L}}(\bm{\mathrm{\xi}})$ with $\mathrm{supp}(H_{\mathcal{L}}) \subset \mathcal{L_0}$, 
which is achieved by
$H_{\mathcal{L}}(\bm{\mathrm{\xi}}) = \mathrm{box}( \bm{\mathrm{A}}^{-1} \bm{\mathrm{\xi}} )$.
Using the stretching property of the Fourier transform, we obtain the
impulse response of the filter,</p>

<script type="math/tex; mode=display">h_{\mathcal{L}} (\bm{\mathrm{x}})  = \mathrm{vol}(\mathcal{L}) \, \mathrm{sinc}(\bm{\mathrm{A}}^\Tr \bm{\mathrm{x}}).</script>

<p>Real anti-aliasing filters are never ideal, therefore some amount of
aliasing is always present in real systems.</p>

<h2 id="interpolation">Interpolation</h2>

<p>Sampling theorem tells us that when a function $f$ is band-limited on
the lattice $\mathcal{L} = {\bm{\mathrm{A}}} \mathbb{Z}^d$ (that is,
$ \mathrm{supp}(F) \subset {\bm{\mathrm{A}}}\left[-\frac{1}{2},\frac{1}{2}\right]^d$),
it can be perfectly reconstructed from its samples
$f|_{\mathcal{L}^\ast}$ on the dual lattice
$\mathcal{L}^\ast = {\bm{\mathrm{A}}}^{\ast} \mathbb{Z}^d$, where
${\bm{\mathrm{A}}}^\ast = {\bm{\mathrm{A}}}^{-\Tr}$, by the following
formula</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
f(\bm{\mathrm{x}}) &=  \sum_{\bm{\mathrm{p}} \in \mathcal{L}^\ast } f(\bm{\mathrm{p}}) \, \mathrm{sinc}(\bm{\mathrm{A}}^{\Tr} ( \bm{\mathrm{x}} - \bm{\mathrm{p}})) 
=  \sum_{\bm{\mathrm{n}} \in \mathbb{Z}^d} f(\bm{\mathrm{A}}^\ast \bm{\mathrm{n}}) \, \mathrm{sinc}(\bm{\mathrm{A}}^{\Tr} \bm{\mathrm{x}} - \bm{\mathrm{n}}).
\end{aligned} %]]></script>

<p>Let us examine the expression</p>

<script type="math/tex; mode=display">\mathrm{sinc}({\bm{\mathrm{A}}}^{\Tr} {\bm{\mathrm{x}}} - {\bm{\mathrm{n}}}) = \mathrm{sinc}(\langle {\bm{\mathrm{a}}}_1, {\bm{\mathrm{x}}} \rangle - n_1) \cdots  \mathrm{sinc}(\langle {\bm{\mathrm{a}}}_d, {\bm{\mathrm{x}}} \rangle - n_d).</script>

<p>Remembering that $\mathrm{sinc}(0) = 1$ and $\mathrm{sinc}(n) = 0$ for
every $n \in \mathbb{Z} \setminus { 0 }$, we obtain that for every
${\bm{\mathrm{p}}} \in \mathcal{L}^\ast$, we can write
${\bm{\mathrm{p}}} = {\bm{\mathrm{A}}}^\ast {\bm{\mathrm{k}}}$ for
${\bm{\mathrm{k}}} \in \mathbb{Z}^d$, obtaining</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
\mathrm{sinc}({\bm{\mathrm{A}}}^{\Tr} {\bm{\mathrm{A}}}^\ast {\bm{\mathrm{k}}} - {\bm{\mathrm{n}}}) &= \mathrm{sinc}({\bm{\mathrm{k}}} - {\bm{\mathrm{n}}}) = \mathrm{sinc}(k_1 - n_1) \cdots  \mathrm{sinc}(k_d - n_d) \\
&= \left\{ \begin{array}{cl} 1 & : {\bm{\mathrm{k}}} = {\bm{\mathrm{n}}} \\ 0 & : \mathrm{otherwise.} \end{array}  \right.
\end{aligned} %]]></script>

<p>This means that on the points of the lattice $\mathcal{L}^\ast$, the
interpolation formula yields exactly the sampled values.</p>

<h3 id="interpolation-kernels">Interpolation kernels</h3>

<p>The problem with the sinc is that it has infinite support. In real
systems, the interpolation formula takes place in an analog piece of
hardware (e.g., electronics or optics), which is limited to simpler
functions with finite support. A real interpolation formula is therefore
a revisited version of its ideal counterpart,</p>

<script type="math/tex; mode=display">f(\bm{\mathrm{x}}) =    \sum_{\bm{\mathrm{n}} \in \mathbb{Z}^d} f(\bm{\mathrm{A}}^\ast \bm{\mathrm{n}}) \, p(\bm{\mathrm{A}}^{\Tr} \bm{\mathrm{x}} - \bm{\mathrm{n}}),</script>

<p>where $p$ is a $d$-dimensional <em>interpolation</em> or <em>reconstruction
kernel|</em> having the property that $p(\bm{\mathrm{0}}) = 1$ and
$p|_{\mathbb{Z}^d \setminus {  \bm{\mathrm{0}}} } = 0$. In practice,
a <em>separable</em> kernel $p(\bm{\mathrm{x}}) = p(x_1)\cdots p(x_d)$ is
often used. The one-dimensional kernel $p$ again has to satisfy
$p(0) = 1$ and $p(n)=0$ for $n \in \mathbb{Z} \setminus {0}$. The
following interpolation kernels are frequently used:</p>

<ul>
  <li>
    <p><em>Zeroth-order</em> or <em>nearest-neighbor interpolation</em>:
$p(x) = \mathrm{rect}(x)$. In case of one-dimensional signals, a
causal version of this kernel,
$p(x) = \mathrm{rect}\left(x-\frac{1}{2}\right)$ is used.
Zeroth-order interpolation sets the value of the continuous-domain
function to the value of the nearest (causal in the latter case)
discrete sample.</p>
  </li>
  <li>
    <p><em>First-order</em> or <em>(multi-) linear interpolation</em>:
$p(x) =  \max (  1 - |x|, 0 )$. First-order interpolation continues
the function between the samples linearly, essentially connecting
the samples by lines (hyperplanes in the $d$-dimensional case).
Bi-linear interpolation is the particular case for $d=2$.</p>
  </li>
  <li>
    <p><em>Third-order</em> or <em>(multi-) cubic interpolation</em>:</p>

    <script type="math/tex; mode=display">% <![CDATA[
p(x) = \left\{ \begin{array}{ll} 
(a+2) |x|^3 - (a+3) |x|^2 + 1  & : |x| \le 1 \\
a|x|^3 - 5a|x|^2 + 8a|x| - 4a & : 1 < |x| < 2 \\
0 & : \mathrm{otherwise}.
\end{array}  \right. %]]></script>

    <p>The parameter $a$ is usually set to $a=-0.5$
or $a=-0.75$. Cubic interpolation essentially fits a cubic Hermite
spline to the data. Bi-cubic interpolation is the particular case
for $d=2$.</p>
  </li>
  <li>
    <p><em>Lanczos interpolation</em>:</p>

    <script type="math/tex; mode=display">% <![CDATA[
p(x) = \left\{ \begin{array}{ll} 
\mathrm{sinc}(x) \, \mathrm{sinc}\left( \frac{x}{a} \right)  & : |x| < a \\
0 & : \mathrm{otherwise}.
\end{array}  \right. %]]></script>

    <p>The parameter $a$ is a positive integer,
typically 2 or 3, which determines the size of the kernel. The
Lanczos kernel has $2a − 1$ lobes: a positive one at the center, and
$a − 1$ alternating negative and positive lobes on each side. As
long as the parameter $a$ is a positive integer, the Lanczos kernel
is continuous everywhere, and its derivative is defined and
continuous everywhere (including $x = \pm a$, where both sinc
functions go to zero). Therefore, the reconstructed signal too will
be $\mathcal{C}^1$.</p>
  </li>
</ul>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>Technically, test functions must be sufficiently well-behaved. We
will not dwell on these subtleties; in practice, any smooth
compactly supported function will suffice for our purpose. <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>In finite-dimensional spaces, the space of linear functionals is
isomorphic to the vector space itself, and distributions are just a
funny way to define vectors through their inner products with test
vectors. On the other hand, in infinitely-dimensional spaces, such
as our spaces of functions, no such isomorphism exists.
Consequently, every function can be described as a distribution, but
there are distributions such as the $\delta$ that cannot be
described by a function. It can be approximated to an desired
accuracy by a sequence of functions, but the limit point of the
sequence is not a function. <a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

        
      </section>

      <footer class="page__meta">
        
        


        
      </footer>

      

      
  <nav class="pagination">
    
      <a href="/cs236860/semesters/w1819/lecture_notes/lecture_1/" class="pagination--pager" title="Lecture 1: Multidimensional signals and systems
">Previous</a>
    
    
      <a href="/cs236860/semesters/w1819/lecture_notes/lecture_3/" class="pagination--pager" title="Lecture 3: Discrete-domain signals and systems
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><input type="text" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
    <div id="results" class="results"></div></div>
      </div>
    

    <div class="page__footer">
      <footer>
        
<!-- Technion and VISTA logos --><script>

var logo_element = '\
<div class="technion-logo"> \
    <a href="https://cs.technion.ac.il"> \
        <img src="/cs236860/semesters/w1819/assets/images/cs_technion-logo.png" alt="Technion"> \
    </a> \
</div> \
';

document
    .querySelector('.masthead__inner-wrap')
    .insertAdjacentHTML('afterbegin', logo_element);

var logo_element = '\
<div class="vista-logo"> \
    <a href="https://vista.cs.technion.ac.il" > \
        <img src="/cs236860/semesters/w1819/assets/images/vista-logo-bw.png" alt="VISTA"> \
    </a> \
</div> \
';

var footerNodes = document.getElementsByTagName("FOOTER")
var footerNode = footerNodes[footerNodes.length - 1];
footerNode.insertAdjacentHTML('afterend', logo_element);

</script>
<!-- Mathjax support --><!-- see: http://haixing-hu.github.io/programming/2013/09/20/how-to-use-mathjax-in-jekyll-generated-github-pages/ -->
<!-- also: http://docs.mathjax.org/en/latest/tex.html for defning mathjax macros -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
      equationNumbers: { autoNumber: "AMS" },
      noErrors: { disabled: true },
      Macros: {
        // Each def here is an array: [<macro>, <num_params>]
        // Aviv's defs
        bold: ["{\\bf #1}",1],
        m: ["\\boldsymbol {#1}",1],             // matrix
        mt: ["\\boldsymbol {#1}^\\top",1],      // transposed matrix
        v: ["\\boldsymbol {#1}",1],             // vector
        vt: ["\\boldsymbol {#1}^\\top",1],      // transposed vector
        diag: ["\\mathop{\\mathrm{diag}}"],
        trace: ["\\mathop{\\mathrm{tr}}"],
        rank: ["\\mathop{\\mathrm{rank}}"],
        set: ["\\mathbb {#1}",1],
        rvar: ["\\mathrm{#1}",1],               // random variable
        rvec: ["\\boldsymbol{\\mathrm{#1}}",1], // random vector

        // Alex's defs
        Tr: ["\\mathrm{T}"],
        RR: ["\\mathbb{R}"],
        Sym: ["\\mathrm{Sym}"],
        Conv: ["\\mathrm{Conv}"],
        trace: ["\\mathrm{tr}"],
        diag: ["\\mathrm{diag}"],
        Acal: ["\\mathcal{A}"],
        Bcal: ["\\mathcal{B}"],
        Pcal: ["\\mathcal{P}"],
        Dcal: ["\\mathcal{D}"],
        Scal: ["\\mathcal{S}"],
        Ab: ["\\bb{A}"],
        Bb: ["\\bb{B}"],
        Pb: ["\\bb{P}"],
        Qb: ["\\bb{Q}"],
        Db: ["\\bb{D}"],
        Fb: ["\\bb{F}"],
        Gb: ["\\bb{G}"],
        Hb: ["\\bb{H}"],
        Xb: ["\\bb{X}"],
        Ib: ["\\bb{I}"],
        Ub: ["\\bb{U}"],
        Rb: ["\\bb{R}"],
        Eb: ["\\bb{E}"],
        Nb: ["\\bb{N}"],
        Mb: ["\\bb{M}"],
        Sb: ["\\bb{S}"],
        fb: ["\\bb{f}"],
        ub: ["\\bb{u}"],
        qb: ["\\bb{q}"],
        rb: ["\\bb{r}"],
        vb: ["\\bb{v}"],
        cb: ["\\bb{c}"],
        Pib: ["\\bb{\\Pi}"],
        Lambdab: ["\\bb{\\Lambda}"],
        alphab: ["\\bb{\\alpha}"],
        gammab: ["\\bb{\\gamma}"],
        Pir: ["\\mathrm{\\Pi}"],
        Sr: ["\\mathrm{S}"],
        Dr: ["\\mathrm{D}"],
        Cr: ["\\mathrm{C}"],
        dis: ["\\mathrm{dis}"],
        dim: ["\\mathrm{dim}"],
        rank: ["\\mathrm{rank}"],
        vec: ["\\mathrm{vec}"],
        conv: ["\\mathrm{conv}"],
        epi: ["\\mathrm{epi}"],
        sgn: ["\\mathrm{sign}"],
        prox: ["\\operatorname{prox}"],
        gradient: ["\\nabla"],
        argmin: ["\\underset{#1}{\operatorname{argmin}}",1],
        argmax: ["\\underset{#1}{\operatorname{argmax}}",1],
        mypara: ["\\noindent \\bf{#1. }",1],
        st: ["\,\,\,\, \\mathrm{s.t.}\,\,"],
        ii: ["i"],
        fff: ["\\,\\,\\displaystyle{\\longleftrightarrow}^{\\mathcal{F}}\\,\\"],

        bm: ["{\\bf #1}",1],
        bb: ["{\\bf{\\mathrm{#1}}}",1],
        spn: ["\\mathrm{span}\\left\\{ {#1} \\right\\}",1],

        vec: ["\\mathrm{vec}"],
        dx:  ["\\bb{dx}"], dX:  ["\\bb{dX}"], dy:  ["\\bb{dy}"], du:  ["\\bb{du}"],
        df:  ["\\bb{df}"], dg:  ["\\bb{dg}"],
        dphi:  ["\\bb{d\\varphi}"],
        Tr: ["\\top"],
        RR: ["\\set{R}"],
        mathpzc: ["\\rvar{#1}", 1],
        mathpzcb: ["\\rvec{#1}", 1],
        mathbbl: ["{\\bf{\\mathrm{#1}}}",1],
        ind: ["\\unicode{x1D7D9}"],
        bed: ["\\mathrm{III}"]
      }
    },

  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [ ['$$','$$'] ],
    processEscapes: true,
  },

  "HTML-CSS": {
     fonts: ["TeX"]
  },

});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<!-- Copyright notice support on single pages -->
<script>
var copyright_element = '\
    <p class="page__meta" style="margin-top: -0.5em;"> \
    <i class="far fa-copyright"></i> \
    Prof. Alex Bronstein \
    </p> \
';

first_header = document.getElementsByTagName('header')[0]
first_header.insertAdjacentHTML('beforeend', copyright_element);
</script>


        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://vista.cs.technion.ac.il"><i class="fas fa-fw fa-link" aria-hidden="true"></i> VISTA Lab</a></li>
        
      
        
          <li><a href="https://github.com/vistalab-technion"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
    

    <li><a href="/cs236860/semesters/w1819/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2019 VISTA Lab. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/cs236860/semesters/w1819/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.2.0/js/all.js"></script>




<script src="/cs236860/semesters/w1819/assets/js/lunr/lunr.min.js"></script>
<script src="/cs236860/semesters/w1819/assets/js/lunr/lunr-store.js"></script>
<script src="/cs236860/semesters/w1819/assets/js/lunr/lunr-en.js"></script>





  </body>
</html>